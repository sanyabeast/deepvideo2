# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üåç GLOBAL CONFIGURATION
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# This file contains global settings that apply to all projects.
# Project-specific configs will be merged with this global config.

# LLM Configuration

llm:
  default_model: "amoral-gemma3-12b-v2-qat"  # Your local LLM model name
  seed: 0  # Will be randomized at runtime if not specified

# Voice Generation Configuration
voice:
  # TTS provider to use ("zonos" or "orpheus")
  provider: "orpheus"
  
  # Zonos provider settings
  zonos_settings:
    # URL to your Zonos TTS server
    tts_server: "http://localhost:5001/generate"
    # Speech rate for Zonos TTS (higher = faster)
    speech_rate: "15"
    # Voice samples to use
    voice_samples:
      - "C:\\ML\\database\\voice\\ai1-en-US-Joseph.mp3"
      - "C:\\ML\\database\\voice\\ai1-en-US-Jack.mp3"
      - "C:\\ML\\database\\voice\\ai2-STD-en-US-Soren.mp3"
      - "C:\\ML\\database\\voice\\ai2-Robert2.mp3"
      - "C:\\ML\\database\\voice\\ai2-en-US-Katie2.mp3"
      - "C:\\ML\\database\\voice\\ai2-en-US-Isabella2.mp3"
      - "C:\\ML\\database\\voice\\ai2-Stacy.mp3"
      - "C:\\ML\\database\\voice\\ai3-Aria.mp3"
  
  # Orpheus provider settings
  orpheus_settings:
    # URL to your Orpheus TTS server
    tts_server: "http://localhost:5005/v1/audio/speech"
    # Model name for Orpheus TTS
    model: "orpheus"
    # Voice presets to use
    voice_presets: ["leah", "dan", "leo", "jess"]
    # Speed factor (0.1 to 1.0, lower is slower)
    speed: 1
  
  # Audio post-processing settings
  postprocessing:
    # Audio normalization settings
    normalization:
      target_db: -20.0  # Target dB level for audio normalization
      enabled: true     # Whether to automatically normalize generated voice lines
    # Silence trimming settings
    silence_trimming:
      enabled: false     # Whether to trim silence from the end of voice lines
      max_silence_sec: 1.0  # Maximum silence to keep at the end in seconds
      threshold_db: -50  # Threshold in dB below which audio is considered silence
    # Tempo manipulation settings (not enabled by default)
    tempo:
      enabled: false  # Set to true to enable
      factor: 0.9     # < 1.0 slows down, > 1.0 speeds up
    # Echo effect settings (not enabled by default)
    echo:
      enabled: false  # Set to true to enable
      delay: 0.1      # Delay in seconds
      decay: 0.1      # Echo volume decay (0-1)

# Video Generation Configuration
video:
  # ImageMagick configuration
  imagemagick_binary: "C:\\Dev\\ImageMagick\\magick.exe"  # Path to ImageMagick binary

  # Volume settings
  background_music_volume: 0.2  # Volume multiplier for background music (0.0 to 1.0)
  voice_narration_volume: 1.0   # Volume multiplier for voice narration (0.0 to 1.0)
  use_consistent_font: true     # Use the same font for all slides in a scenario
  intro_delay: 1.0              # Delay in seconds before the first slide appears
  outro_delay: 2.0              # Delay in seconds after the last slide before the video ends
  voice_line_delay: 0.25        # Delay in seconds after each voice line before the next slide

  # Emoji settings
  emoji:
    enabled: true               # Whether to render emojis in videos (true = enabled, false = disabled)
    font: "lib/noto_sans_emoji.ttf"  # Path to emoji font file (relative to project root)
    scale: 1.5                 # Scale factor for emoji size (1.0 = normal, 1.5 = 50% larger)
    rotation:
      enabled: true            # Whether to randomly rotate emojis
      min_angle: -30           # Minimum rotation angle in degrees
      max_angle: 30            # Maximum rotation angle in degrees

# Image Generation Configuration
images:
  enabled: false  # Set to false to disable image generation
  comfy_server_address: "127.0.0.1:8188"  # URL to the ComfyUI server
  steps: 12  # Number of steps for image generation
  default_negative_prompt: "text, watermark, signature, blurry, distorted, low resolution, poorly drawn, bad anatomy, deformed, disfigured, out of frame, cropped"  # Default negative prompt
  generation_timeout: 60  # Maximum wait time in seconds for image generation
  # The workflow is a JSON representation of the ComfyUI workflow
  # This is a basic example using Flux model, but you can export your own workflow from ComfyUI
  # Special placeholders:
  # {PROMPT} - Will be replaced with the slide's background_image_description
  # {NEGATIVE_PROMPT} - Will be replaced with the default_negative_prompt
  # {SEED} - Will be replaced with a random seed
  # {STEPS} - Will be replaced with the steps value
  workflow: |
    {
      "5": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "6": {
        "inputs": {
          "text": "{PROMPT}",
          "clip": [
            "11",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "13",
            0
          ],
          "vae": [
            "10",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "9": {
        "inputs": {
          "filename_prefix": "flux/image",
          "images": [
            "8",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      },
      "10": {
        "inputs": {
          "vae_name": "ae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "Load VAE"
        }
      },
      "11": {
        "inputs": {
          "clip_name1": "t5xxl-fp8-e4m3fn.safetensors",
          "clip_name2": "clip-l.safetensors",
          "type": "flux",
          "device": "default"
        },
        "class_type": "DualCLIPLoader",
        "_meta": {
          "title": "DualCLIPLoader"
        }
      },
      "12": {
        "inputs": {
          "unet_name": "flux.1s-fp8.safetensors",
          "weight_dtype": "default"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "Load Diffusion Model"
        }
      },
      "13": {
        "inputs": {
          "noise": [
            "25",
            0
          ],
          "guider": [
            "22",
            0
          ],
          "sampler": [
            "16",
            0
          ],
          "sigmas": [
            "17",
            0
          ],
          "latent_image": [
            "5",
            0
          ]
        },
        "class_type": "SamplerCustomAdvanced",
        "_meta": {
          "title": "SamplerCustomAdvanced"
        }
      },
      "16": {
        "inputs": {
          "sampler_name": "euler"
        },
        "class_type": "KSamplerSelect",
        "_meta": {
          "title": "KSamplerSelect"
        }
      },
      "17": {
        "inputs": {
          "scheduler": "simple",
          "steps": {STEPS},
          "denoise": 1,
          "model": [
            "12",
            0
          ]
        },
        "class_type": "BasicScheduler",
        "_meta": {
          "title": "BasicScheduler"
        }
      },
      "22": {
        "inputs": {
          "model": [
            "12",
            0
          ],
          "conditioning": [
            "6",
            0
          ]
        },
        "class_type": "BasicGuider",
        "_meta": {
          "title": "BasicGuider"
        }
      },
      "25": {
        "inputs": {
          "noise_seed": {SEED}
        },
        "class_type": "RandomNoise",
        "_meta": {
          "title": "RandomNoise"
        }
      }
    }

# Media Options
media_options:
  music_files_count: 16  # Number of music files to show in scenario generation
  video_files_count: 16  # Number of video files to show in scenario generation

# Emotions List
emotions:
  - "happiness"
  - "sadness"
  - "disgust"
  - "fear"
  - "surprise"
  - "anger"
  - "neutral"

# Prompt Configuration
prompts:
  # Topics generation prompt
  topics:
    role: "You are a creative and insightful motivational content strategist for short-form video platforms (TikTok, Reels, YouTube Shorts)."
    instruction: "Generate a list of 5 **fresh and unconventional motivational video topics**. Avoid clich√©, overused ideas like \"overcoming fear\" or \"imposter syndrome\". Be unique, thought-provoking, and modern."
    requirements:
      - "Be specific and catchy"
      - "Appeal to younger audiences (Gen Z, Millennials)"
      - "Spark curiosity or emotion"
      - "Be suitable for short, powerful videos"
      - "Use only plain ENGLISH words and phrases."
      - "Do NOT include emojis, icons, or non-standard symbols."
      - "Do NOT use non-English languages or phrases."
  
  # Scenario generation prompt
  scenario:
    role: "You are a short-form video copywriter crafting motivational videos for TikTok, Reels, and YouTube Shorts."
    instruction: "Create a **micro-story split into short slides** (like Instagram story frames) for the topic: \"{topic}\""
    constraints:
      - "Total video duration: **8-16 seconds max**"
      - "Each slide: **very short sentence or phrase**, 3‚Äì8 words"
      - "Each slide duration: **1 to 4 seconds** (max)"
      - "Max 8 slides"
    style:
      - "Ultra-punchy and emotionally charged"
      - "Hooks the viewer in slide 1"
      - "Builds emotional or motivational momentum"
      - "Uses rhythm, repetition, shock, or questions"
      - "Ends strong with a bold punchline or insight"
      - "Use everyday, casual Gen Z language"
      - "Use only plain ENGLISH for all text."
      - "Do NOT include emojis, emoticons, icons, or non-standard symbols."
      - "Do NOT include non-English words, slang from other languages, or cultural references that may require translation."

# Directory Configuration
directories:
  # Input directories
  videos_dir: "lib/videos"
  music_dir: "lib/music"
  fonts_dir: "lib/fonts"
  emoji_fonts_dir: "lib/fonts_emoji"
  
  # Output directories (will be created under output/{project_name}/)
  scenarios: "scenarios"
  voice_lines: "voice_lines"
  output_videos: "videos"
  images: "images"
